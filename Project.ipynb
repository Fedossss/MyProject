{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7837bcaaf33cf883",
   "metadata": {},
   "source": [
    "# Задание\n",
    "В папке с заданием Вы найдете:\n",
    "\n",
    "\n",
    "*   файл train.csv, содержащий обучающую выборку и соответствующие значения целевой переменной;\n",
    "*   файл test.csv, содержащий тестовую выборку без соответствующих значений целевой переменной;\n",
    "*   файлы users.csv, users_friends.csv, games_details.csv, achievements_stats.csv, содержающие дополнительные данные, которые могут помочь при решении задачи;\n",
    "*   файл simple_pipeline.ipynb, содержащий подробное описание данных и пример получения столбца значений целевой переменной для открытой тестовой выборки;\n",
    "*   файл sample_submission.csv, содержащий пример корректной посылки.\n",
    "\n",
    "# Постановка задачи\n",
    "Объектами изучения в этом задании будут пользователи онлайн-магазина компьютерных игр Steam и сами игры. Основная величина, которую требуется предсказать, -- это время, проведенное пользователем в той или иной игре. Пользователи при этом описываются датой регистрации, дружескими связями, достижениями и другими признаками, а про игры известна их жанровая принадлежность и разметка по некоторым другим тегам (подробнее -- в ноутбуке). Вам предлагается проверить гипотезу о зависимости времени, проведенного пользователем в игре, от свойств игры и статистики самого пользователя и разработать модель машинного обучения для восстановления этой зависимости.\n",
    "# Evaluation\n",
    "Оценка качества модели определяется с помощью вычисления rMSLE (root mean squared logarithmic error) -- корня из среднеквадратической ошибки.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4aa4737792537",
   "metadata": {},
   "source": [
    "# Описание решения\n",
    "\n",
    "В основе решения лежит feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a9b4e0084aaec",
   "metadata": {},
   "source": [
    "1. Объединить датасеты c train/test\n",
    "2. Исключить столбец profilestate из-за его неинформативности (все значения равны 1).\n",
    "3. Обучить модель на числовых данных с помощью LightGBM без дополнительной обработки датасета <font color=\"green\">(Улучшение)</font>.\n",
    "4. Создать категориальный признак, выделив топ N самых популярных игр, остальные обозначить как \"Other\" <font color=\"green\">(Улучшение)</font>.\n",
    "5. Выполнить one-hot кодирование тегов для топ N игр <font color=\"green\">(Улучшение)</font>.\n",
    "6. Применить one-hot кодирование для жанров игр <font color=\"green\">(Улучшение)</font>.\n",
    "7. Сагрегировать данные по достижениям:\n",
    "    1. Определить достижение с наименьшим процентом выполнения среди игроков <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Посчитать количество достижений <font color=\"red\">(Ухудшение)</font>.\n",
    "    3. Определить количество скрытых достижений <font color=\"green\">(Улучшение)</font>.\n",
    "8. Ввести временной признак с момента выхода игры и создания профиля в Steam <font color=\"green\">(Улучшение)</font>.\n",
    "9. Данные о друзьях:\n",
    "    1. Число друзей <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Поскольку большинство пользователей имеют не более 5 друзей в датасете, дальнейшая агрегация данных о них нецелесообразна.\n",
    "10. Оптимизировать значение N для категорийных признаков (из пункта 4 и 5), выбирая параметры по популярности и стандартному отклонению, чтобы в тренировочной выборке было не менее 50 образцов <font color=\"blue\">(не дало сильного прироста)</font>.\n",
    "11. Число игр, в которые играл пользователь <font color=\"green\">(Улучшение)</font>.\n",
    "12. Обнаружено, что 99% пользователей в тестовой выборке известны в тренировочной, что позволяет агрегацию данных о пользователях, включая все игры, в которые они играли.\n",
    "13. Агрегировать среднее количество часов, проведенных в онлайн и оффлайн играх, с осторожностью тестировать <font color=\"orange\">(агрегация признака исключительно на обучающей выборке, чтобы избежать утечки данных)</font> и тестировать аналогичные признаки:\n",
    "    1. Агрегировать признаки на части обучающей выборки <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Среднее время для каждой игры <font color=\"green\">(Улучшение)</font>.\n",
    "    3. Вычислить уровень увлеченности пользователя:\n",
    "    <font color=\"green\">(Улучшение)</font>\n",
    "$$\n",
    "Увлеченность(N, M) = \\text{(Число минут для пользователя N в игре M)} - \\text{(Среднее число минут для игры M)}\n",
    "$$\n",
    "Среднее время по игре рассчитывается без учета нулевых значений. Уровень увлеченности пользователя определяется как:\n",
    "$$\n",
    "Увлеченность(N) = \\frac{1}{|games(N)|} \\sum_{M \\in games(N)} Увлеченность(N, M)\n",
    "$$\n",
    "    4. Определить признак $\\text{среднее\\_время\\_игры(M) + Увлеченность(N)}$ <font color=\"green\">(Улучшение)</font>.\n",
    "14. Эксперименты с графом друзей с использованием networkx:\n",
    "    1. Количество \"команд\" для каждой игры (число компонент связности подграфа игры) <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Расстояние до самого дальнего человека в \"команде\" (эксцентриситет вершины в подграфе игры) <font color=\"green\">(Улучшение)</font>.\n",
    "    3. Число самой сообщенной команды (максимальная клика в подграфе игры) <font color=\"red\">(Ухудшение)</font>.\n",
    "    4. Комбинация признаков из пунктов 3 и 4 <font color=\"red\">(Ухудшение)</font>.\n",
    "15. Эксперименты с друзьями относительно игры:\n",
    "    1. Среднее число друзей у игроков <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Среднее число друзей, играющих в данную игру <font color=\"green\">(Улучшение)</font>.\n",
    "    3. Среднее число друзей друзей, играющих в данную игру <font color=\"green\">(Улучшение)</font>.\n",
    "    4. Среднее число друзей друзей у игроков <font color=\"green\">(Улучшение)</font>.\n",
    "16. One-hot кодирование первых N популярных игр, в которые играл пользователь <font color=\"green\">(Улучшение)</font>.\n",
    "\n",
    "17. Количество времени, проведенное в топ 100 популярных играх, с учетом переобучения:\n",
    "    1. Если в train/test нет семпла пользователя с какой-то игрой, ставить 0, если неизвестно – NaN <font color=\"red\">(Ухудшение)</font>.\n",
    "    2. Если в train/test нет семпла пользователя с какой-то игрой, ставить -1, если неизвестно – NaN, увеличивая информативность признаков <font color=\"red\">(Ухудшение)</font>.\n",
    "18. Оптимизировать N для пункта 10 <font color=\"green\">(Улучшение)</font>.\n",
    "19. Число игроков в каждой игре в пределах датасета <font color=\"green\">(Улучшение)</font>.\n",
    "20. Дополнительный анализ данных о друзьях:\n",
    "    1. Среднее число друзей у игроков <font color=\"green\">(Улучшение)</font>.\n",
    "    2. Среднее число друзей, играющих в данную игру <font color=\"green\">(Улучшение)</font>.\n",
    "    3. Среднее число друзей друзей, играющих в данную игру <font color=\"green\">(Улучшение)</font>.\n",
    "    4. Среднее число друзей друзей у игроков <font color=\"green\">(Улучшение)</font>.\n",
    "21. Количество друзей друзей <font color=\"red\">(Ухудшение)</font>.\n",
    "22. Число игроков, известных из train/test и achievements_stats.csv, играющих в ту же игру:\n",
    "    1. Друзья <font color=\"blue\">(не дало сильного прироста)</font>.\n",
    "    2. Друзья друзей <font color=\"red\">(Ухудшение)</font>.\n",
    "23. Доля жанров для каждого игрока <font color=\"green\">(Улучшение)</font>.\n",
    "24. Доля жанра для игрока в текущей игре <font color=\"green\">(Улучшение)</font>.\n",
    "25. Любимый жанр в текущей игре <font color=\"green\">(Улучшение)</font>.\n",
    "26. Исключить personastate, так как он не информативен без дополнительных характеристик пользователя <font color=\"red\">(Ухудшение)</font>.\n",
    "27. Работа с рейтингами игр:\n",
    "    1. Средний рейтинг игр для пользователя <font color=\"red\">(Ухудшение)</font>.\n",
    "    2. Разница среднего рейтинга игр пользователя и рейтинга игры <font color=\"red\">(Ухудшение)</font>.\n",
    "28. Число игр, в которые пользователь играл за последние 2 недели <font color=\"green\">(Улучшение)</font>.\n",
    "29. Число игр, в которые пользователь активно играл (больше 2 часов за последние 2 недели) <font color=\"red\">(Ухудшение)</font>.\n",
    "30. Среднее время, проведенное в игре за последние 2 недели.\n",
    "31. Определить оптимальную верхнюю границу времени создания аккаунта и выхода игры, нижняя граница – время игры за последние 2 недели <font color=\"blue\">(не дало сильного прироста)</font>.\n",
    "32. Использовать user_id как признак, оставив 10% \"неизвестными\" <font color=\"red\">(Ухудшение)</font>.\n",
    "33. Использовать CatBoost и оптимизировать параметры на фиксированной валидации/тесте <font color=\"green\">(Улучшение)</font>.\n",
    "34. Анализ семплов с наибольшей ошибкой (распределение ошибок примерно как нормальное, но выделить общие черты не удалось)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a673be31f63812",
   "metadata": {},
   "source": [
    "# Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9431d02239e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:29:13.711237Z",
     "start_time": "2024-08-03T13:29:12.075011Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os.path import isdir\n",
    "import plotly.express as ply\n",
    "from functools import partial\n",
    "from os.path import isfile\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebafe24861c5de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:30:05.253878Z",
     "start_time": "2024-08-03T13:30:05.149824Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "PATH = \"./\"\n",
    "SUBMISSION_PATH = \"./submission.csv\"\n",
    "PRECOMPUTED_PATH = \"./\"\n",
    "\n",
    "train_data = pd.read_csv(f\"{PATH}train.csv\")\n",
    "test_data = pd.read_csv(f\"{PATH}test.csv\")\n",
    "target = train_data.playtime_forever\n",
    "train_data.drop(columns='playtime_forever', inplace=True)\n",
    "\n",
    "target = np.log1p(target)   # Преобразуем для перехода от RMSLE к RMSE\n",
    "categorical_features = []\n",
    "bad_features = []           # Признаки, которые удалим   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0878bd4868b24d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_achievement_features(x: pd.Series): \n",
    "    '''\n",
    "    Число достижений, число секретных достижений, лучшее достижение для игрока\n",
    "    '''\n",
    "    temp = x.dropna().explode().dropna()\n",
    "    if temp.shape[0] == 0:\n",
    "        return (0, 0, 1.0)\n",
    "    temp = pd.DataFrame(temp.tolist(), columns=['name', 'secret', 'achieved'])\n",
    "    temp.drop_duplicates(subset=['name'], inplace=True)\n",
    "    return (temp.shape[0], temp.secret.sum(), temp.achieved.min())\n",
    "\n",
    "def fetch_neighbors(target, graph=None, depth=1, return_previous_n=True): \n",
    "    '''\n",
    "    Получение соседей неболее чем за depth\n",
    "    '''\n",
    "    temp2 = nx.single_source_shortest_path_length(graph, target, cutoff=depth) \n",
    "    del temp2[iter(temp2.keys()).__next__()]\n",
    "    if return_previous_n:\n",
    "        temp2 = pd.Series(temp2)\n",
    "        ans = []\n",
    "        for i in range(1, n):\n",
    "            ans.append(list(temp2.loc[(temp2 <= i).values].index))\n",
    "        ans.append(list(temp2.index))\n",
    "    else:\n",
    "        ans = list(temp2.keys())\n",
    "    return ans\n",
    "\n",
    "\n",
    "\n",
    "if isfile(PRECOMPUTED_PATH + \"aggregated.pkl\"):  # Есть предпосчитанный файл\n",
    "    aggregated = pd.read_pickle(PRECOMPUTED_PATH + \"aggregated.pkl\")\n",
    "    categorical_features += ['communityvisibilitystate', 'personastate']\n",
    "else:  \n",
    "    # aggregated - признаки из train и test, чтобы аггрегировать признаки к ним вместе\n",
    "    aggregated = pd.concat([train_data[['user_id', 'game_id', 'game_name', 'playtime_2weeks']], test_data[['user_id', 'game_id', 'game_name', 'playtime_2weeks']]])\n",
    "    aggregated.index = np.arange(aggregated.shape[0])\n",
    "    \n",
    "    # выкидываем повторы из achievements_stats.csv и джоиним\n",
    "    achievement_stats = pd.read_csv(PATH + \"achievements_stats.csv\",converters={'achievements': lambda x: [] if pd.isnull(x) else eval(x)})\n",
    "    achievement_stats.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    achievement_stats.drop_duplicates(subset=['user_id', 'game_id'], keep='last', inplace=True, ignore_index=True)\n",
    "    aggregated = aggregated.merge(achievement_stats, how='left', on=['user_id', 'game_id'])\n",
    "    \n",
    "    # players_by_game в котором индекс соответсвует game_id, а значение списку игроков\n",
    "    players_by_game = pd.concat([achievement_stats[['user_id', 'game_id']], aggregated[['user_id', 'game_id']]])\n",
    "    players_by_game.drop_duplicates(subset=['user_id', 'game_id'], keep='last', inplace=True, ignore_index=True)\n",
    "    players_by_game = players_by_game.groupby('game_id')['user_id'].agg(lambda x: list(x))\n",
    "    \n",
    "    # Обрабатываем достижения через extract_achievement_features\n",
    "    achievements_aggregated = achievement_stats.groupby('game_id')['achievements'].agg(extract_achievement_features)\n",
    "    temp = pd.Series([(0, 0, 1.0) for i in range(aggregated.shape[0])])\n",
    "    mask = aggregated.loc[:, 'game_id'].isin(achievements_aggregated.index).values\n",
    "    temp.loc[mask] = achievements_aggregated[aggregated.loc[mask, 'game_id'].values].values\n",
    "    aggregated[\"achieve_params\"] = temp.values\n",
    "    \n",
    "    # присоединяем games_details.csv и подстанавливаем первую дату выхода укзананных игр\n",
    "    game_details = pd.read_csv(PATH + \"games_details.csv\", index_col=0, converters={'genres': lambda x: eval(x), 'tags': lambda x: eval(x)})\n",
    "    game_details.loc[game_details.game_id == 602960, 'release_date'] = '2019-06-05'  # Barotrauma\n",
    "    game_details.loc[game_details.game_id == 1740720, 'release_date'] = '2022-03-08' # Have a Nice Death\n",
    "    game_details.loc[game_details.game_id == 230410, 'release_date'] = '2013-03-25'  # Warframe\n",
    "    game_details.loc[game_details.game_id == 1105670, 'release_date'] = '2021-06-03' # The Last Spell\n",
    "    aggregated = aggregated.merge(game_details, how='left', on=['game_id'])\n",
    "    \n",
    "    # присоединяем users.csv\n",
    "    user_data = pd.read_csv(PATH + \"users.csv\", index_col=0)\n",
    "    aggregated = aggregated.merge(temp, how='left', on=['user_id'])\n",
    "    categorical_features += ['communityvisibilitystate', 'personastate']\n",
    "    aggregated.release_date = pd.to_datetime(aggregated.release_date).dt.date\n",
    "    aggregated.timecreated = pd.to_datetime(aggregated.timecreated)\n",
    "    \n",
    "    # Представление users_friends.csv в виде графа\n",
    "    friends_data = pd.read_csv(PATH + \"users_friends.csv\", index_col=0)\n",
    "    friends_graph = nx.from_pandas_edgelist(temp, 'user_id', 'friend_id')\n",
    "    \n",
    "    # Аггрегация графовых признаков (самое долгое)\n",
    "    aggregated['max_clique'] = np.nan   # Самая большая клика подграфа игры, в которой состоит игрок\n",
    "    aggregated['eccentricity'] = np.nan # Эксцентриситет\n",
    "    connected_components_count = {}     # Число компонент связности в подграфе игры\n",
    "    clique_number = {}                  # Кликовое число подграфа игры\n",
    "    for game in aggregated.game_id.unique():  # Идея 31\n",
    "        users = aggregated.loc[(aggregated.game_id == game).values, 'user_id'].values\n",
    "        users = sorted(list(set(temp.nodes) & set(users)))\n",
    "        if len(users) == 0:\n",
    "            continue\n",
    "        game_subgraph = nx.induced_subgraph(temp, players_by_game.loc[game])  # Подграф игры\n",
    "        # Вычисление эксцентриситета\n",
    "        eccentricity = {}\n",
    "        connected_components = list(nx.connected_components(game_subgraph))  # Компоненты связности\n",
    "        connected_components_count[game] = len(connected_components)\n",
    "        for connected in connected_components:  # Чтобы обойти ошибку с несвязными подграфами, считаем эксцентриситет лишь на компонентах связности\n",
    "            temp4 = nx.induced_subgraph(game_subgraph, connected)\n",
    "            eccentricity.update(nx.eccentricity(temp4, sorted(list(set(users) & set(connected)))))\n",
    "        users1 = aggregated.loc[(aggregated.game_id == game).values, 'user_id']\n",
    "        aggregated.loc[(aggregated.game_id == game).values, 'eccentricity'] = users1.map(eccentricity)\n",
    "        \n",
    "        largest_clique_size = max(len(clique) for clique in nx.find_cliques(game_subgraph))\n",
    "        \n",
    "        clique_number[game] = largest_clique_size\n",
    "        aggregated.loc[(aggregated.game_id == game).values, 'max_clique'] = users1.map(nx.node_clique_number(game_subgraph, nodes=users))\n",
    "    aggregated['components'] = aggregated.game_id.map(connected_components_count).values\n",
    "    aggregated['clique_number'] = aggregated.game_id.map(clique_number).values\n",
    "    \n",
    "    # Аггрегация друзей \n",
    "    user_neighbors = pd.DataFrame({\"user_id\": aggregated.user_id.unique()})\n",
    "    temp = user_neighbors.user_id.apply(partial(fetch_neighbors, graph=game_details, n=2))\n",
    "    user_neighbors['friends'] = temp.str[0]\n",
    "    user_neighbors['friends_of_friends'] = temp.str[1]\n",
    "    aggregated = aggregated.merge(user_neighbors, how='left', on=['user_id'])\n",
    "    aggregated['friends_played_same'] = 0\n",
    "    aggregated['friends_of_friends_played_same'] = 0\n",
    "    for game, i in zip(aggregated.game_id.values, np.arange(aggregated.shape[0])):\n",
    "        temp = pd.Series(aggregated.friends_of_friends.iloc[i]).isin(players_by_game[game]).values\n",
    "        aggregated.iloc[i, -1] = temp.sum()\n",
    "        aggregated.iloc[i, -2] = temp[:len(aggregated.friends.iloc[i])].sum()\n",
    "        \n",
    "    aggregated.to_pickle(PRECOMPUTED_PATH + \"aggregated.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3700d5783c97064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMES_N_BORDER = 150\n",
    "TAGS_N_BORDER = 150\n",
    "precomputed_sets = {'pop': {}, 'var': {}}\n",
    "\n",
    "\n",
    "def filter_list(x, replace=True, temp=[]):\n",
    "    \"\"\"\n",
    "    Убирает из списка элементы, не содержащиеся в x, если replace=True, то при наличии отличных элементов от\n",
    "    элементов из temp добавляется строка \"__other__\"\n",
    "    \"\"\"\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return []\n",
    "    flag = False\n",
    "    ans = []\n",
    "    for i in x:\n",
    "        if i in temp:\n",
    "            ans.append(i)\n",
    "        else:\n",
    "            flag = True\n",
    "    if flag and replace:\n",
    "        ans.append(\"__other__\")\n",
    "    return ans\n",
    "\n",
    "if isfile(PRECOMPUTED_PATH + \"games_tags.pkl\"):\n",
    "    with open(PRECOMPUTED_PATH + \"games_tags.pkl\", 'rb') as f:\n",
    "        precomputed_sets = pickle.load(f)\n",
    "else:\n",
    "    # Временно присоединяем target к aggregated для сбора статистики об играх и тегах\n",
    "    stats = aggregated.iloc[:train_data.shape[0], :].loc[:, ['game_name', 'tags']].join(target)\n",
    "    \n",
    "    # Сбор игр с самой малой дисперсией по target в датасете игр\n",
    "    games_variance = aggregated.iloc[:train_data.shape[0], :].game_name.value_counts(sort=True)\n",
    "    games_variance = games_variance[games_variance.values > 50].index\n",
    "    games_variance = stats.groupby('game_name')['playtime_forever'].agg('std').loc[games_variance.values].sort_values(ascending=True, kind=\"stable\").index[:GAMES_N_BORDER]\n",
    "    precomputed_sets['var']['list_games'] = games_variance\n",
    "    \n",
    "    # Самые популярные игры\n",
    "    temp = aggregated.game_name.value_counts(sort=True)\n",
    "    precomputed_sets['pop']['list_games'] = temp.index[:GAMES_N_BORDER]\n",
    "    \n",
    "    # Самые популярные теги\n",
    "    temp = aggregated.tags.explode().value_counts(sort=True)\n",
    "    temp = temp.index[:TAGS_N_BORDER]\n",
    "    precomputed_sets['pop']['list_tags'] = temp\n",
    "    \n",
    "    # Получение one-hot по объединению тегов по популярности и дисперсии\n",
    "    temp = aggregated.iloc[:train_data.shape[0], :].tags.explode().value_counts(sort=True)\n",
    "    temp = temp[temp.values > 50].index\n",
    "    temp2 = aggregated.iloc[:train_data.shape[0], :].tags.apply(partial(filter_list, replace=False, temp=temp))\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    temp2 = pd.DataFrame.sparse.from_spmatrix(\n",
    "                    mlb.fit_transform(temp2),\n",
    "                    columns=mlb.classes_)\n",
    "    total = {}\n",
    "    for i in temp2.columns:\n",
    "        total[i] = target.loc[temp2[i].astype(pd.SparseDtype(bool))].std()\n",
    "    total = pd.Series(total).sort_values(ascending=True, kind=\"stable\").index[:TAGS_N_BORDER]\n",
    "    precomputed_sets['var']['list_tags'] = total\n",
    "    temp = sorted(list(set(precomputed_sets['var']['list_tags']) | set(precomputed_sets['pop']['list_tags'])))\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "    temp2 = aggregated.tags.apply(partial(filter_list, replace=False, temp=temp))\n",
    "    temp2 = pd.DataFrame(\n",
    "                    mlb.fit_transform(temp2),\n",
    "                    columns=[f'tag_{i}' for i in mlb.classes_])\n",
    "    precomputed_sets['tag_set'] = temp2\n",
    "    # Сохранение\n",
    "    with open(PRECOMPUTED_PATH + \"games_tags.pkl\", 'wb') as f:\n",
    "        pickle.dump(precomputed_sets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bdaa301a9bcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры полученные через optuna\n",
    "N_GAME_POP = 19\n",
    "N_GAME_VAR = 20\n",
    "N_TAG_POP = 43\n",
    "N_TAG_VAR = 8\n",
    "def contains_other_tag(x, temp=[]):\n",
    "    \"\"\"\n",
    "    Возвращает 1, если есть элемент в x отличный от элементов из temp, иначе 0\n",
    "    \"\"\"\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return 0\n",
    "    flag = False\n",
    "    for i in x:\n",
    "        if i not in temp:\n",
    "            flag = True\n",
    "            break\n",
    "    return int(flag)\n",
    "\n",
    "# Получаем списки игр и добавляем признаки по играм/тегам\n",
    "games_list = sorted(list(set(precomputed_sets['pop']['list_games'][:N_GAME_POP]) | set(precomputed_sets['var']['list_games'][:N_GAME_VAR])))\n",
    "tags_list = sorted(list(set(precomputed_sets['pop']['list_tags'][:N_TAG_POP]) | set(precomputed_sets['var']['list_tags'][:N_TAG_VAR])))\n",
    "temp = aggregated.game_name.copy(deep=True)\n",
    "temp.loc[~(temp.isin(games_list))] = 'Other'\n",
    "aggregated.loc[:, 'game_name_label'] = LabelEncoder().fit_transform(temp)\n",
    "feats_list = [f\"tag_{i}\" for i in tags_list]\n",
    "categorical_features += feats_list\n",
    "categorical_features.append(\"tag___other__\")\n",
    "categorical_features.append('game_name_label')\n",
    "aggregated = aggregated.join(precomputed_sets['tag_set'].loc[:, feats_list])\n",
    "aggregated.loc[:, \"tag___other__\"] = aggregated.tags.apply(partial(contains_other_tag, temp=feats_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0438b9e5cad7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_achievement(x):  \n",
    "    '''\n",
    "    Самое редкое достижение у пользователя \n",
    "    '''\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return np.nan\n",
    "    ans = 1.0\n",
    "    for i in x:\n",
    "        if ans > i[2]:\n",
    "            ans = i[2]\n",
    "    return ans\n",
    "\n",
    "def count_achievements(x):  \n",
    "    \"\"\"\n",
    "    Количество достижений\n",
    "    \"\"\"\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return np.nan\n",
    "    return len(x)\n",
    "\n",
    "\n",
    "def secret_achievement_ratio(x):  \n",
    "    '''\n",
    "    Доля скрытых достижений у пользователя\n",
    "    '''\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return np.nan\n",
    "    if len(x) == 0:\n",
    "        return 0.0\n",
    "    ans = 0\n",
    "    for i in x:\n",
    "        ans += int(i[1])\n",
    "    return ans / len(x)\n",
    "\n",
    "def count_secret_achievements(x):  \n",
    "    \"\"\"\n",
    "    Количество скрытых достижений у пользователя \n",
    "    \"\"\"\n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return np.nan\n",
    "    if len(x) == 0:\n",
    "        return 0\n",
    "    ans = 0\n",
    "    for i in x:\n",
    "        ans += int(i[1])\n",
    "    return ans\n",
    "\n",
    "\n",
    "aggregated['achieve_best'] = aggregated.achievements.apply(main_achievement)\n",
    "aggregated['achieve_count'] = aggregated.achievements.apply(count_achievements)\n",
    "aggregated['achieve_hided'] = aggregated.achievements.apply(secret_achievement_ratio)\n",
    "aggregated['achieve_hided_count'] = aggregated.achievements.apply(count_secret_achievements)\n",
    "aggregated['achieve_completed'] = aggregated['achieve_count'] / aggregated.achieve_params.str[0]\n",
    "aggregated['achieve_hided_completed'] = aggregated['achieve_hided_count'] / aggregated.achieve_params.str[1]\n",
    "aggregated['total_achievements'] = aggregated.achieve_params.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb86a6bfc656478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_list(x):  \n",
    "    if not isinstance(x, list) and pd.isnull(x):\n",
    "        return []\n",
    "    return x\n",
    "\n",
    "# OHE жанров\n",
    "aggregated.genres = aggregated.genres.apply(replace_nan_with_list)\n",
    "mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "aggregated = aggregated.join(\n",
    "            pd.DataFrame(\n",
    "                mlb.fit_transform(aggregated.pop('genres')),\n",
    "                index=aggregated.index,\n",
    "                columns=[f\"genre_{i}\" for i in mlb.classes_]))\n",
    "categorical_features += [f\"genre_{i}\" for i in mlb.classes_]\n",
    "genres_list = [f\"genre_{i}\" for i in mlb.classes_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d57b47486ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = aggregated.groupby('user_id')\n",
    "aggregated['games_played'] = temp['game_id'].agg('count')[aggregated.user_id.values].values\n",
    "aggregated['total_2weeks_playtime'] = temp['playtime_2weeks'].agg('sum')[aggregated.user_id.values].values\n",
    "aggregated['total_achievements'] = temp['achieve_count'].agg(np.nansum)[aggregated.user_id.values].values \n",
    "aggregated['best_achieve_ever'] = temp['achieve_best'].agg(np.nanmin)[aggregated.user_id.values].values \n",
    "\n",
    "for feat in genres_list: # Доля жанров игр для игрока\n",
    "    aggregated[feat + '_played'] = temp[feat].agg(\"mean\")[aggregated.user_id.values].values\n",
    "aggregated['played_genre_ratio'] = np.max(aggregated.iloc[:, -len(genres_list):-1].values, axis=1)\n",
    "temp2 = aggregated.iloc[:, -len(genres_list):].values\n",
    "temp2[~(aggregated.loc[:, genres_list].values.astype(bool))] = -1\n",
    "aggregated['curr_game_genre_ratio'] = np.max(temp2, axis=1) # Самая большая доля среди жанров\n",
    "temp2 = np.argmax(temp2, axis=1)\n",
    "aggregated['curr_game_genre'] = np.array(genres_list)[temp2] # Самый проигрываемый жанр для игрока\n",
    "temp2 = aggregated.curr_game_genre_ratio == -1\n",
    "aggregated.loc[temp2.values, 'curr_game_genre'] = 'Unknown' # Если жанры неизвестны\n",
    "aggregated.loc[:, 'curr_game_genre_labeled'] = LabelEncoder().fit_transform(aggregated.loc[:, 'curr_game_genre'].values) # Числовые значения для curr_game_genre\n",
    "categorical_features.append('curr_game_genre_labeled')\n",
    "aggregated['mean_rating'] = temp['rating'].agg(np.nanmean)[aggregated.user_id.values].values \n",
    "aggregated['rating_normed'] = aggregated.rating.values - aggregated.mean_rating.values # Разница рейтинга игры и прошлого признака\n",
    "\n",
    "aggregated['games_played_in_2weeks'] = temp['playtime_2weeks'].agg(lambda x: (x > 0).sum())[aggregated.user_id.values].values\n",
    "aggregated['games_actively_played_in_2weeks'] = temp['playtime_2weeks'].agg(lambda x: (x > 120).sum())[aggregated.user_id.values].values\n",
    "bad_features += ['played_genre_ratio', 'mean_rating', 'rating_normed', 'games_actively_played_in_2weeks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2616adf403a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = aggregated.groupby('game_id')\n",
    "aggregated['mean_playtime_2weeks'] = temp['playtime_2weeks'].agg(np.nanmean)[aggregated.game_id.values].values\n",
    "aggregated['players_count'] = temp['user_id'].agg('count')[aggregated.game_id.values].values\n",
    "moment = pd.Series([pd.to_datetime('2023-03-09')] * aggregated.shape[0])\n",
    "aggregated['release_date'] = pd.to_datetime(aggregated['release_date'])\n",
    "aggregated['release_diff'] = (moment - aggregated['release_date']).dt.days\n",
    "aggregated['account_time'] = (moment - aggregated['timecreated']).dt.total_seconds() / (60 * 60 * 24)\n",
    "aggregated['friends_count'] = aggregated.friends.apply(lambda x: 0 if (not isinstance(x, list) and pd.isnull(x)) else len(x))\n",
    "aggregated['friends_of_friends_count'] = aggregated.friends_of_friends.apply(lambda x: 0 if (not isinstance(x, list) and pd.isnull(x)) else len(x))\n",
    "# Среднее число друзей игроков из игры\n",
    "aggregated['mean_friends'] = temp['friends_count'].agg(np.nanmean)[aggregated.game_id.values].values\n",
    "# Среднее число друзей игроков из игры, которые играют в эту же игру\n",
    "aggregated['mean_friends_played_same'] = temp['friends_played_same'].agg(np.nanmean)[aggregated.game_id.values].values\n",
    "# Среднее число друзей друзей игроков из игры, которые играют в эту же игру\n",
    "aggregated['mean_friends_of_friends_played_same'] = temp['friends_of_friends_played_same'].agg(np.nanmean)[aggregated.game_id.values].values\n",
    "# Среднее число друзей игроков из игры, которые играют в эту же игру\n",
    "aggregated['mean_friends_of_friends'] = temp['friends_of_friends_count'].agg(np.nanmean)[aggregated.game_id.values].values\n",
    "\n",
    "# Отношение максимальной клики для игрока к кликовому числу подграфа игры\n",
    "aggregated['max_clique_norm'] = aggregated.max_clique.values / aggregated.clique_number.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aeddc80eecbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot самых популярных игр, в которые играл пользователь\n",
    "temp = aggregated.groupby(\"user_id\")[\"game_name\"]\\\n",
    "                 .agg(lambda x: list(x.unique()))\\\n",
    "                 .apply(partial(filter_list, replace=False, temp=precomputed_sets['pop']['list_games'][:100]))\n",
    "temp = pd.DataFrame({\"user_id\": temp.index, \"games\": temp.values})\n",
    "mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "temp = temp.join(pd.DataFrame(\n",
    "                mlb.fit_transform(temp.games),\n",
    "                columns=[f'game_{i}_played' for i in mlb.classes_]))\n",
    "categorical_features += [f'game_{i}_played' for i in mlb.classes_]\n",
    "temp.drop(columns=[\"games\"], inplace=True)\n",
    "aggregated = aggregated.merge(temp, how=\"left\", on=\"user_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d548c9e03a89e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEK_TOP_GAMES = 100\n",
    "top_games = aggregated.game_id.value_counts(sort=True, ascending=False).index[:SEEK_TOP_GAMES]\n",
    "y_extended = pd.Series(data=-2.0, index=np.arange(aggregated.shape[0]))\n",
    "y_extended.iloc[:train_data.shape[0]] = target.values\n",
    "aggregated[\"y_ext\"] = y_extended.values\n",
    "\n",
    "temp = aggregated.groupby([\"user_id\", \"game_id\"])[\"y_ext\"].agg('sum')\n",
    "top_games = pd.Series(top_games)\n",
    "arr = []\n",
    "for user in aggregated.user_id.unique():\n",
    "    arr.append(top_games.map(temp[user]).values)\n",
    "arr = np.vstack(arr)\n",
    "arr[np.isnan(arr)] = -1.0\n",
    "arr[arr == -2] = np.nan\n",
    "arr = pd.DataFrame(arr, columns=[f\"time_{i}_played\" for i in top_games.values])\n",
    "arr[\"user_id\"] = aggregated.user_id.unique()\n",
    "aggregated = aggregated.merge(arr, how=\"left\", on=\"user_id\")\n",
    "\n",
    "indexes_games = pd.Series(np.arange(SEEK_TOP_GAMES), index=top_games.values)\n",
    "for i in range(train_data.shape[0]):\n",
    "    if aggregated.game_id.iloc[i] in top_games.values:\n",
    "        aggregated.iloc[i, -100 + indexes_games.loc[aggregated.game_id.iloc[i]]] = np.nan\n",
    "aggregated.drop(columns=[\"y_ext\"], inplace=True)\n",
    "\n",
    "bad_features += [f\"time_{i}_played\" for i in top_games.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429da5aac2bee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNREDACTED_AGGREGATED = aggregated.copy(deep=True)\n",
    "UNREDACTED_TRAIN = aggregated.iloc[:train_data.shape[0]].copy(deep=True)\n",
    "def get_data(X_on: pd.DataFrame =None, y_on: pd.DataFrame=None, mas=None, apply_to=[], random_state=None, gamma=0.55):\n",
    "    \"\"\"\n",
    "    Создаем признаки для классификации на основе y_on, используя X_on.\n",
    "    \n",
    "    mas: маска для выбора признаков, чтобы не обучаться на всех признаках сразу.\n",
    "    apply_to: наборы данных, к которым мы добавляем новые признаки и возвращаем их после обработки.\n",
    "    random_state: параметр для управления случайностью.\n",
    "    gamma: доля y, известная для агрегации признаков, чтобы модель могла обучаться в условиях, когда некоторые значения отсутствуют.\n",
    "    \"\"\"\n",
    "    rand = np.random.RandomState(random_state)\n",
    "\n",
    "    if X_on is not None and y_on is not None:\n",
    "        X_ondate = X_on\n",
    "        y_ondate = y_on\n",
    "    else:\n",
    "        X_ondate = UNREDACTED_TRAIN.loc[mas]\n",
    "        y_ondate = target.loc[mas]\n",
    "    X_ondate['y'] = y_ondate\n",
    "    mask_gamma = rand.uniform(size=[X_ondate.shape[0]]) < gamma\n",
    "    \n",
    "    ans = []\n",
    "    new_feats = []\n",
    "    new_feats_names = []\n",
    "    grouped_by = []\n",
    "    \n",
    "    temp = X_ondate.loc[(X_ondate.tag_Singleplayer == 1) & mask_gamma].groupby('user_id')['y'].agg('mean')\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('singleplayer_played_mean')\n",
    "    grouped_by.append('user_id')\n",
    "    \n",
    "    temp = X_ondate.loc[(X_ondate.tag_Multiplayer == 1) & mask_gamma].groupby('user_id')['y'].agg('mean')\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('multiplayer_played_mean')\n",
    "    grouped_by.append('user_id')\n",
    "    \n",
    "    temp = X_ondate.loc[mask_gamma].groupby('user_id')['y'].agg('mean')\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('played_mean')\n",
    "    grouped_by.append('user_id')\n",
    "    \n",
    "    temp = X_ondate.loc[mask_gamma].groupby('game_id')['y'].agg('mean')\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('games_played_mean')\n",
    "    grouped_by.append('game_id')\n",
    "    \n",
    "    temp = X_ondate.loc[mask_gamma].groupby('game_name_label')['y'].agg(lambda x: np.nanmean(x > np.log1p(120)))\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('game_played_more_2h')\n",
    "    grouped_by.append('game_name_label')\n",
    "    \n",
    "    transformer = X_ondate.groupby('game_id')['y'].agg('mean')\n",
    "    temp = pd.Series(np.nan, index=np.arange(X_ondate.shape[0]))\n",
    "    mask = X_ondate.loc[:, 'game_id'].isin(transformer.index).values\n",
    "    temp.loc[mask] = transformer[X_ondate.loc[mask, 'game_id'].values].values\n",
    "    y_temp = pd.Series(np.nan, index=np.arange(X_ondate.shape[0]))\n",
    "    y_temp.loc[mask_gamma] = (X_ondate.y.values - temp.values)[mask_gamma]\n",
    "    temp = pd.DataFrame({'user_id': X_ondate.user_id, 'y': y_temp.values})\n",
    "    temp = temp.groupby('user_id')['y'].agg('mean')\n",
    "    new_feats.append(temp)\n",
    "    new_feats_names.append('activity_on_game')\n",
    "    grouped_by.append('user_id')\n",
    "\n",
    "    \n",
    "    X_ondate.drop(columns=['y'], inplace=True)\n",
    "    apply_list = [X_ondate] # Список всех датасетов, к которым применяется преобразование\n",
    "    apply_list += apply_to\n",
    "    for X_dataset in apply_list:\n",
    "        for name, transformer, grouped_on in zip(new_feats_names, new_feats, grouped_by):\n",
    "            temp = pd.Series(np.nan, index=np.arange(X_dataset.shape[0]))\n",
    "            mask = X_dataset.loc[:, grouped_on].isin(transformer.index).values\n",
    "            temp.loc[mask] = transformer[X_dataset.loc[mask, grouped_on].values].values\n",
    "            X_dataset[name] = temp.values\n",
    "        temp = pd.Series(np.nan, index=np.arange(X_dataset.shape[0]))\n",
    "        mask = (X_dataset.tag_Singleplayer == 1).values\n",
    "        temp.loc[mask] = X_dataset.loc[mask, 'singleplayer_played_mean']\n",
    "        mask = (X_dataset.tag_Multiplayer == 1).values\n",
    "        temp.loc[mask] = X_dataset.loc[mask, 'multiplayer_played_mean']\n",
    "        X_dataset['played_on_tag'] = temp.values\n",
    "        X_dataset['activity_game_played_mean'] = X_dataset.games_played_mean + X_dataset.activity_on_game\n",
    "        ans.append(X_dataset)\n",
    "    return tuple(ans)\n",
    "bad_features.append('game_played_more_2h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e3a99f966fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_trunc(X_test, y_test: pd.Series):\n",
    "    \"\"\"\n",
    "        Функция, которая подгоняет y под временные рамки признаков:\n",
    "        1. Если y < np.log1p(playtime_2weeks), то у = np.log1p(playtime_2weeks)\n",
    "        2. Если y > np.log1p(release_diff * 24 * 60 * C), то y = np.log1p(release_diff * 24 * 60 * C), C = 0.3\n",
    "        3. Если y > np.log1p(account_time * 24 * 60 * C), то y = np.log1p(account_time * 24 * 60 * C), C = 0.1\n",
    "    \"\"\"\n",
    "    upper = pd.Series(np.inf, index=X_test.index)\n",
    "    temp = np.log1p(X_test.account_time.copy() * 24 * 60 * 0.1)\n",
    "    temp.loc[temp.isna().values] = np.inf\n",
    "    upper.loc[upper.values > temp.values] = temp.loc[upper > temp].values\n",
    "    temp = X_test.release_diff.copy()\n",
    "    temp.loc[temp.values < 0] = 0\n",
    "    temp = np.log1p(temp.values * 24 * 60 * 0.3)\n",
    "    temp[np.isnan(temp)] = np.inf\n",
    "    upper.loc[upper.values > temp] = temp[upper.values > temp]\n",
    "    y_test.loc[y_test.values > upper.values] = upper.loc[y_test.values > upper.values].values\n",
    "    temp = np.log1p(X_test.playtime_2weeks)\n",
    "    y_test.loc[y_test.values < temp.values] = temp[y_test.values < temp.values].values\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c6aec91564d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features += [\"game_id\", \"user_id\", \"profilestate\", 'achieve_count', 'achieve_hided_count', 'friends_of_friends_played_same', 'friends_of_friends_count', 'clique_number'] + list(aggregated.columns[(aggregated.dtypes == object) | (aggregated.dtypes == 'datetime64[ns]')])\n",
    "bad_features = sorted(list(set(bad_features) & set(aggregated.columns)))\n",
    "categorical_all = deepcopy(categorical_features)\n",
    "categorical_features = sorted(list(set(categorical_features) - set(bad_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473841e42364b3f",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f3bcf8a9bded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_aggr = aggregated.iloc[:train_data.shape[0], :].copy()\n",
    "test_set_aggr = aggregated.iloc[train_data.shape[0]:, :].copy()\n",
    "CAT_PARAMS={'max_depth': 12,\n",
    "            'max_leaves': 164,\n",
    "            'min_child_samples': 34,\n",
    "            'reg_lambda': 3.977768225983847,\n",
    "            'grow_policy': 'Lossguide',\n",
    "            'n_estimators': 5000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95376006bc82496",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_set_aggr, target, test_size=0.05, random_state=RANDOM_STATE)\n",
    "X_train, X_val, test_set_aggr = get_data(X_train, y_train, apply_to=[X_val, test_set_aggr], random_state=RANDOM_STATE)\n",
    "X_train.drop(columns=bad_features, inplace=True)\n",
    "X_val.drop(columns=bad_features, inplace=True)\n",
    "test_set_aggr.drop(columns=bad_features, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e09880731f6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(random_state=RANDOM_STATE, **CAT_PARAMS)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=(X_val, y_val),\n",
    "              early_stopping_rounds=100,\n",
    "              cat_features=categorical_features,\n",
    "              use_best_model=True,\n",
    "              metric_period=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d44b17e01b30d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    preds = model.predict(test_set_aggr)\n",
    "preds = pred_trunc(test_set_aggr, pd.Series(preds))\n",
    "preds = np.expm1(preds)\n",
    "submission = pd.DataFrame({\"index\": test_data[\"index\"],\n",
    "                           \"playtime_forever\": preds})\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178de02edff80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "answers = []\n",
    "TRIES = 10\n",
    "for tries in range(TRIES):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(UNREDACTED_AGGREGATED.iloc[:train_data.shape[0]], target, test_size=0.1, random_state=tries)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=tries)\n",
    "    X_train, X_val, X_test = get_data(X_train, y_train, apply_to=[X_val, X_test], gamma=0.58, random_state=tries)\n",
    "    X_train.drop(columns=bad_features, inplace=True)\n",
    "    X_val.drop(columns=bad_features, inplace=True)\n",
    "    X_test.drop(columns=bad_features, inplace=True)\n",
    "    model = CatBoostRegressor(verbose=-1, random_state=tries, **CAT_PARAMS)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=(X_val, y_val),\n",
    "                  early_stopping_rounds=60,\n",
    "                  cat_features=categorical_features,\n",
    "                  use_best_model=True,\n",
    "                  verbose=False)\n",
    "        temp = model.predict(X_test)\n",
    "    temp = pred_trunc(X_test, pd.Series(temp))\n",
    "    temp2 = mean_squared_error(y_test, temp, squared=False)\n",
    "    answers.append(temp2)\n",
    "    print(f\"Current RMSE: {temp2}, mean: {np.mean(answers)}\")\n",
    "answers = np.array(answers)\n",
    "var = np.std(answers)\n",
    "answers.sort()\n",
    "print(f\"Error = {np.mean(answers[1:-1])}, std = {var}, mean std = {var / np.sqrt(TRIES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe3e0233b9b0a4",
   "metadata": {},
   "source": [
    "Оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1535102f71c5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "X_train, X_test, y_train, y_test = train_test_split(UNREDACTED_AGGREGATED.iloc[:train_data.shape[0]], target, test_size=0.1, random_state=42)\n",
    "# X_train, X_test = get_data(X_train, y_train, apply_to=[X_test])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train, X_val, X_test = get_data(X_train, y_train, apply_to=[X_val, X_test], gamma=0.58, random_state=42)\n",
    "X_train.drop(columns=bad_features, inplace=True)\n",
    "X_val.drop(columns=bad_features, inplace=True)\n",
    "X_test.drop(columns=bad_features, inplace=True)\n",
    "def func(trial: optuna.Trial):\n",
    "    sample_params = {\n",
    "        'n_estimators': 1000000,\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 7, 15),\n",
    "        'max_leaves': trial.suggest_int(\"max_leaves\", 5, 200, log=True),\n",
    "        'min_child_samples': trial.suggest_int(\"min_child_samples\", 1, 300, log=True),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 1e-3, 100.0, log=True),\n",
    "        'grow_policy': 'Lossguide',\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = CatBoostRegressor(**sample_params)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=(X_val, y_val),\n",
    "                  early_stopping_rounds=100,\n",
    "                  cat_features=categorical_features,\n",
    "                  use_best_model=True,\n",
    "                  verbose=False)\n",
    "        temp = model.predict(X_test)\n",
    "    temp = pred_trunc(X_test, pd.Series(temp))\n",
    "    temp2 = mean_squared_error(y_test, temp, squared=False)\n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc83b1b173556cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optuna.create_study(sampler=optuna.samplers.TPESampler(n_startup_trials=100), direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec956bf927030de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.optimize(func, n_trials=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1274c032f8e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faca2fc270a7abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
